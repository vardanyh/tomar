import os
import re

def get_corrected_map():
    """
    Combines the standard map with explicit overrides for the 
    errors you identified (i instead of r, etc.)
    """
    mapping = {
        # --- The Critical Overrides (Based on your feedback) ---
        0x95: '\u0580', # Was 'i', now 'r' (Ö€) - Fixes ÔµÕ«Õ¯ -> ÔµÖ€Õ¯
        0xf3: '\u0582', # Was 'Ã³', now 'v/u' (Ö‚) - Fixes ÕˆÃ³Õ« -> ÕˆÖ‚Ö€
        0xe1: '\u0549', # Was 'Ã¡', now 'Ch' (Õ‰) - Fixes Ã¡Õ¸Õ« -> Õ‰Õ¸Ö€
        0xf7: '\u0584', # Was 'Ã·', now 'q' (Ö„) - Fixes ÔµÕ«Õ¥Ã· -> ÔµÖ€Õ¥Ö„
        0xe9: '\u057d', # Was 'Ã©', now 's' (Õ½) - Fixes Õ€Õ¸Õ£Õ¥Õ£Õ¡Õ¬Ã©Õ¿ -> Õ€Õ¸Õ£Õ¥Õ£Õ¡Õ¬Õ½Õ¿
        0xf8: '\u0555', # Was 'Ã¸', now 'O' (Õ•) - Fixes Ã¸Õ«Õ¡Ö -> Õ•Ö€Õ¡Ö
        
        # --- Previous Fixes (Confirmed Correct) ---
        0xec: '\u0551', # Ã¬ -> Õ (Ton)
        0xf1: '\u0581', # Ã± -> Ö (Tsuyts)
        0xea: '\u054e', # Ãª -> Õ (Vardavar)
        0xeb: '\u057e', # Ã« -> Õ¾ (anvanum)
        0xe7: '\u057c', # Ã§ -> Õ¼ (Vardavari)
        0xe8: '\u0550', # Ã¨ -> Õ (Surb)
        0xf4: '\u0553', # Ã´ -> Õ“ (Pokhman)
        0xe4: '\u0584', # Ã¶ -> Ö„ (Hamarjeq)
        0xed: '\u057f', # Ã­ -> Õ¿ (aynuhetev)
        0xfe: '\u0587', # Ã¾ -> Ö‡ (aynuhetev)
        0xf9: '\u0585', # Ã¹ -> Ö… (Orery)
        0xfc: '\u0580', # Ã¼ -> Ö€ (Vor)
        0xa9: '\u0585', # Â© -> Ö… (Standard)
        0xb0: '\u055B', # Õ› (Shesht)
        
        # --- Missing Chars Inferred ---
        0xdf: '\u0569', # Õ© (to)
        0xef: '\u056f', # k (ken) - Confirmed for Yerku (Monday)
    }
    
    # --- Background Map (Even/Odd Logic) ---
    upper_arm = "Ô±Ô²Ô³Ô´ÔµÔ¶Ô·Ô¸Ô¹ÔºÔ»Ô¼Ô½Ô¾Ô¿Õ€ÕÕ‚ÕƒÕ„Õ…Õ†Õ‡ÕˆÕ‰ÕŠÕ‹ÕŒÕÕÕÕÕ‘Õ’Õ“Õ”Ö‡Õ•Õ–"
    lower_arm = "Õ¡Õ¢Õ£Õ¤Õ¥Õ¦Õ§Õ¨Õ©ÕªÕ«Õ¬Õ­Õ®Õ¯Õ°Õ±Õ²Õ³Õ´ÕµÕ¶Õ·Õ¸Õ¹ÕºÕ»Õ¼Õ½Õ¾Õ¿Ö€ÖÖ‚ÖƒÖ„Ö‡Ö…Ö†"
    
    for i in range(30):
        byte_upper = 0x80 + (i * 2)
        byte_lower = 0x81 + (i * 2)
        if byte_upper not in mapping:
            mapping[byte_upper] = upper_arm[i]
        # Only add lower if we haven't overridden it (prevents 0x95 -> i)
        if byte_lower not in mapping:
            mapping[byte_lower] = lower_arm[i]

    return mapping

def phrase_polish(text):
    """
    Manual replacement for specific complex words and phrases 
    provided by the user to guarantee 100% accuracy.
    """
    corrections = {
        # Days of the Week
        "ÔµÕ«Õ¯Õ¸Ã³Õ·Õ¡Õ¢Õ©Õ«": "ÔµÖ€Õ¯Õ¸Ö‚Õ·Õ¡Õ¢Õ©Õ«",
        "ÔµÕ«Õ¥Ã·Õ·Õ¡Õ¢Õ©Õ«": "ÔµÖ€Õ¥Ö„Õ·Õ¡Õ¢Õ©Õ«",
        "Ã¡Õ¸Õ«Õ¥Ã·Õ·Õ¡Õ¢Õ©Õ«": "Õ‰Õ¸Ö€Õ¥Ö„Õ·Õ¡Õ¢Õ©Õ«",
        "ÕˆÃ³Õ«Õ¢Õ¡Õ©": "ÕˆÖ‚Ö€Õ¢Õ¡Õ©",
        
        # Prompts and Phrases
        "Õ‘Õ¸Õ¶Õ¥Õ«Õ« Õ¡Õ¶Õ¾Õ¡Õ¶Õ¸Ã³Õ´Õ¶Õ¥Õ«Õ¨": "ÕÕ¸Õ¶Õ¥Ö€Õ« Õ¡Õ¶Õ¾Õ¡Õ¶Õ¸Ö‚Õ´Õ¶Õ¥Ö€Õ¨",
        "Ã¸Õ«Õ¡ÖÕ¸Ã³Ö…Ö": "Õ•Ö€Õ¡ÖÕ¸Ö‚ÕµÖ", # Inferred based on context "Oratsuyts"
        "Ô¶Õ¡Õ¿Õ¯Õ« Ö…Õ«Õ¥Õ«Õ¨": "Ô¶Õ¡Õ¿Õ¯Õ« Ö…Ö€Õ¥Ö€Õ¨",
        "Õ€Õ¸Õ£Õ¥Õ£Õ¡Õ¬Ã©Õ¿Ö…Õ¡Õ¶ Ö…Õ«Õ¥Õ«Õ¨": "Õ€Õ¸Õ£Õ¥Õ£Õ¡Õ¬Õ½Õ¿Õ¥Õ¡Õ¶ Ö…Ö€Õ¥Ö€Õ¨",
        "ÕÕ¡Õ«Õ¤Õ¡Õ¾Õ¡Õ¼Õ« Ö…Õ«Õ¥Õ«Õ¨": "ÕÕ¡Ö€Õ¤Õ¡Õ¾Õ¡Õ¼Õ« Ö…Ö€Õ¥Ö€Õ¨",
        "Õ“Õ¸Õ­Õ´Õ¡Õ¶ Ô±Ã©Õ¿Õ¾Õ¡Õ®Õ¡Õ®Õ¶Õ« Ö…Õ«Õ¥Õ«Õ¨": "Õ“Õ¸Õ­Õ´Õ¡Õ¶ Ô±Õ½Õ¿Õ¾Õ¡Õ®Õ¡Õ®Õ¶Õ« Ö…Ö€Õ¥Ö€Õ¨",
        "ÕÕ¸Ã³Õ«Õ¢ Ô½Õ¡Ã¡Õ« Õ¿Õ¸Õ¶Õ« Ö…Õ«Õ¥Õ«Õ¨": "ÕÕ¸Ö‚Ö€Õ¢ Ô½Õ¡Õ¹Õ« Õ¿Õ¸Õ¶Õ« Ö…Ö€Õ¥Ö€Õ¨",
        "Õ€Õ«Ã©Õ¶Õ¡Õ¯Õ¡Õ´Õ¸Ã³Õ¿Õ« Ö…Õ«Õ¥Õ«Õ¨": "Õ€Õ«Õ½Õ¶Õ¡Õ¯Õ¡Õ´Õ¸Ö‚Õ¿Õ« Ö…Ö€Õ¥Ö€Õ¨",
        
        # General Fixes for fragments
        "Ö…Õ«Õ¥Õ«Õ¨": "Ö…Ö€Õ¥Ö€Õ¨", # Fixes "orery" generically
        "Õ¸Ã³": "Õ¸Ö‚",       # Fixes "u" generically
        "Ã©Õ¿Ö…Õ¡Õ¶": "Õ½Õ¿Õ¥Õ¡Õ¶", # Fixes "styan" generically
    }
    
    for bad, good in corrections.items():
        text = text.replace(bad, good)
    return text

def final_correction(filepath):
    if not os.path.exists(filepath):
        print(f"âŒ File not found: {filepath}")
        return

    print(f"ğŸ“– Reading {filepath}...")
    with open(filepath, 'rb') as f:
        content = f.read()

    arm_map = get_corrected_map()

    def translate_bytes(match):
        byte_seq = match.group(0)
        result = []
        for b in byte_seq:
            if b in arm_map:
                result.append(arm_map[b])
            else:
                result.append(chr(b))
        return "".join(result)

    # 1. Byte-to-Unicode Translation inside quotes
    pattern = re.compile(b'"([^"\\\\]*(\\\\.[^"\\\\]*)*)"')
    
    def regex_callback(match):
        return translate_bytes(match).encode('utf-8')
        
    # Apply map
    intermediate_bytes = pattern.sub(regex_callback, content)
    intermediate_text = intermediate_bytes.decode('utf-8', errors='ignore')

    # 2. Phrase Polish (The "Safety Net")
    final_text = phrase_polish(intermediate_text)

    output_path = "CORRECTED_SHAHE97.SRC"
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(final_text)
    
    print(f"âœ… Success! Created: {output_path}")
    print("ğŸ‘‰ Please verify: 'ÔµÖ€Õ¯Õ¸Ö‚Õ·Õ¡Õ¢Õ©Õ«', 'ÕÕ¸Ö‚Ö€Õ¢ Ô½Õ¡Õ¹Õ«', 'Õ€Õ¸Õ£Õ¥Õ£Õ¡Õ¬Õ½Õ¿Õ¥Õ¡Õ¶'.")

if __name__ == "__main__":
    final_correction("SHAHE97.SRC")